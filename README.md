# LAB2
EEG Classification with BCI competition dataset

## Datasets
The training and testing data in BCI Competition III â€“ IIIb.
<img src="Source/prepare data.png" width="900">
---

## ğŸ“ Project Structure
```
LAB2/
â”‚
â”œâ”€â”€ models/              # EEGNet and DeepConvNet
â”‚    â”œâ”€â”€ model_ELU.py
â”‚    â”œâ”€â”€ model_ReLU.py
â”‚    â””â”€â”€ model_LeakyReLU.py
â”‚
â”œâ”€â”€ data_LAB2/           # Datasets
â”‚    â”œâ”€â”€ S4b_train.npz
â”‚    â”œâ”€â”€ S4b_test.npz
â”‚    â”œâ”€â”€ X11b_train.npz
â”‚    â””â”€â”€ X11b_test.npz
â”‚ 
â”œâ”€â”€ dataloader.py        # Load data
â”œâ”€â”€ EEGNet_main.py       # Run EEGNet
â”œâ”€â”€ DeepConvNet_main.py  # Run DeepConvNet
â”‚
â”œâ”€â”€ plots_LAB2/          # Accuracy and Loss curves
â”œâ”€â”€ pts_LAB2/            # Trained model weights (.pt)
â””â”€â”€ Source/              
```
---
## Code EEGNet_main.py and DeepConvNet_main.py
For EEGNet model:
- EEGNet_main.py

For DeepConvNet model:
- DeepConvNet_main.py
```
#You could change # to use different `Activation Function` directly.

# EEGNet
from models.model_ELU import EEGNet
#from models.model_ReLU import EEGNet
#from models.model_LeakyReLU import EEGNet

# DeepConvNet
from models.model_ELU import DeepConvNet
#from models.model_ReLU import DeepConvNet
#from models.model_LeakyReLU import DeepConvNet
```
---

## Results
### Hyper Parameters - Set1
- **Batch size:** `64`  
- **Learning rate:** `1e-2`  
- **Epochs:** `150`  
- **Optimizer:** `Adam`  
- **Loss function:** `torch.nn.CrossEntropyLoss()`  
- **Activation function:** `ELU()`
###  Accuracy under Hyper Parameters - Set 1
| Activation Function |  EEGNet  | DeepConvNet |
|:--------------------:|:----------:|:------------:|
| **ELU**        | 85.93% | 81.11% |
### Hyper Parameters - Set2
- **Batch size:** `64`  
- **Learning rate:** `1e-3` (EEGNet) / `1e-4` (DeepConvNet)
- **Epochs:** `1000` (EEGNet) / `3000` (DeepConvNet) 
- **Optimizer:** `Adam`  
- **Loss function:** `torch.nn.CrossEntropyLoss()`  
- **Activation function:** `ELU()` / `ReLU()` / `LeakyReLU()`
### Accuracy under Hyper Parameters - Set 2

| Activation Function |   EEGNet   | DeepConvNet |
|:--------------------:|:----------:|:------------:|
| **ELU**             | **87.13%** |   82.59% |
| **ReLU**        | **87.13%** |   83.15% |
| **LeakyReLU**              |   86.39%   |   82.22% |
---
##Curve
### Accuracy under Hyper Parameters - Set 2
<div style="display: flex; flex-wrap: wrap; gap: 10px;">
  <img src="plots_LAB2/ReLU_EP1000_EEG_train_accuracy.png" width="240">
  <img src="plots_LAB2/ReLU_EP1000_EEG_train_loss.png" width="240">
  <img src="plots_LAB2/ReLU_EP1000_EEG_test_accuracy.png" width="240">
  <img src="plots_LAB2/ReLU_EP1000_EEG_test_loss.png" width="240">
</div>

### Accuracy under Hyper Parameters - Set 2
<div style="display: flex; flex-wrap: wrap; gap: 10px;">
  <img src="plots_LAB2/ReLU_EP1000_EEG_train_accuracy.png" width="240">
  <img src="plots_LAB2/ReLU_EP1000_EEG_train_loss.png" width="240">
  <img src="plots_LAB2/ReLU_EP1000_EEG_test_accuracy.png" width="240">
  <img src="plots_LAB2/ReLU_EP1000_EEG_test_loss.png" width="240">
</div>


